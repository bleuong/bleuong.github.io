{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a reuseable module to preprocess the data file as the first step in any data analysis. It comprise of the following:\n",
    "\n",
    "1. Import data from file\n",
    "2. Take care of missing data\n",
    "3. Encode categorical data if required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # library for numerical manimuplation\n",
    "import matplotlib.pyplot as plt  # library for plotting\n",
    "import pandas as pd  # library for importing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Data Preprocessing Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Preprocessing(InputFileName=None,\n",
    "                       ImputerInput={\"selectedCol\": None, \"strategy\": \"mean\"},\n",
    "                       xEncoderInput={\"cols\": None, \"AvoidDummy\": False},\n",
    "                       yEncoderInput=False):\n",
    "    \"\"\"\n",
    "    This is to import the dataset from the given csv file and process it for\n",
    "    subsequent analysis. The data file must be located in the same folder as\n",
    "    this python script. The processing includes 1) Data import, 2) Fill in\n",
    "    missing values, and 3) Encode categorical data.\n",
    "\n",
    "    When encoding categorical data, the new variables created based on the\n",
    "    categorical values are called dummy variables. It is important to avoid\n",
    "    using all the dummy variables (dummy variable trap) as the model\n",
    "    would be unable to differentiate the relationship. Hence, always use 1 less\n",
    "    dummy variable in the model for each set of categorical variables.\n",
    "\n",
    "    It is important to arrange the dataset columns in the following sequence\n",
    "    from left to right.\n",
    "    1. Numrical data (for filling in of missing values)\n",
    "    2. Categorical data (after encoding, it would be the first few columns in\n",
    "                          the dataset. Remove the first column to avoid dummy\n",
    "                          variable trap before encoding the next categorical\n",
    "                          variable.)\n",
    "    3. Dependent variable\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    InputFileName : This is the name of the file to be imported for analysis.\n",
    "                        The file must be located in the same folder as this\n",
    "                        python script.\n",
    "    ImputerInput : A dict containing a list of columns to fill in the missing\n",
    "                    values and the strategy for the missing values.\n",
    "                    Can be \"mean\", \"median\", \"most_frequent\". If the list\n",
    "                    of columns is None, it means no missing values.\n",
    "    xEncoderInput : A dict containing a list of columns index in x to encode\n",
    "                        the categorical data and a boolen value to indicate if\n",
    "                        there is a need to avoid the dummy variable trap. An\n",
    "                        empty list indicate no need to perform encoding.\n",
    "                        Default is {cols: [], AvoidDummy=False}\n",
    "    yEncoderInput : A boolen value indicating if the dependent variable y is\n",
    "                    categorical data and need to be encoded. Default is False.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : Variable containing the full data after importing from csv file.\n",
    "    imputer : SimpleImputer object created to fill in missing values\n",
    "    ct : ColumnTransformer object created to encode the categorical data in x\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x : Variable containing all independent features. Numpy array type\n",
    "    y : Variable containing all dependent value. Numpy array type\n",
    "\n",
    "    Pseudo Code\n",
    "    -----------\n",
    "    Import data\n",
    "        Import from csv file\n",
    "        Extract to x and y and return them\n",
    "    Take care of missing data\n",
    "        If missing data is less than 1% of the total data, then can just\n",
    "        delete them away.\n",
    "        If there are columns with missing data\n",
    "            Replace with mean/median/most_frequent of existing data.\n",
    "    Encode categorical data\n",
    "        If there are columns in x with categorical data:\n",
    "            Use OneHotEncoder to encode each respective columns\n",
    "            OneHotEncoder will encode and transfer the dummy variables to the\n",
    "            first column of the dataset.\n",
    "        If the dependent variable y is categorical:\n",
    "            Use LabelEncoder to encode\n",
    "    Return x, y\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" Import data \"\"\"\n",
    "    from os import listdir, getcwd\n",
    "    from os.path import isfile, join\n",
    "    from sys import exit\n",
    "\n",
    "    # Get file name if it is not provided\n",
    "    if InputFileName is None:\n",
    "        while True:\n",
    "            print(f\"Current working directory is:\\n{getcwd()}\")\n",
    "            file_list = [f for f in listdir() if isfile(join(f))]\n",
    "            file_list_index = list(range(len(file_list)))\n",
    "            print(\"Files available are:\")\n",
    "            for fli in file_list_index:\n",
    "                print(f\"({fli}) {file_list[fli]}\")\n",
    "            ui = input(\"Please select the corresponding file or -1 to exit \",\n",
    "                       \"if file is not found.\\nPlease ensure data file is in \",\n",
    "                       \"the same directory as the code file.\")\n",
    "            try:\n",
    "                # Check if ui is correctly input\n",
    "                ui = int(ui)\n",
    "                # Input is an integer. Check if it falls in the correct range.\n",
    "                if ui == -1:\n",
    "                    # Exit\n",
    "                    exit\n",
    "                elif ui in file_list_index:\n",
    "                    # Valid option selected. Verify selection\n",
    "                    ui1 = input(f\"You have selected {file_list[ui]}.\\n\",\n",
    "                                \"Please confirm Y/N.\")\n",
    "                    if ui1.upper() == \"Y\":\n",
    "                        # Correct selection. break out of while loop\n",
    "                        InputFileName = file_list[ui]\n",
    "                        break\n",
    "                    elif ui1.upper() == \"N\":\n",
    "                        # Incorrect selection\n",
    "                        pass\n",
    "                    else:\n",
    "                        # Unknown input\n",
    "                        print(\"You have provided an invalid selection.\")\n",
    "                else:\n",
    "                    # Incorrect input. Will raise error exception\n",
    "                    print(\"You have provided an invalid selection.\")\n",
    "            except ValueError:\n",
    "                # Wrong user input\n",
    "                print(\"You have provided an invalid selection.\")\n",
    "    else:\n",
    "        # Date file name provided. Do nothing\n",
    "        pass\n",
    "\n",
    "    # Read data from data file\n",
    "    dataset = pd.read_csv(InputFileName)\n",
    "    print(\"Data imported successfully.\\n\")\n",
    "\n",
    "    print(dataset.info(), \"\\n\")\n",
    "    print(dataset.head())\n",
    "\n",
    "    # Extract the dependent variable (y) and independent features (x).\n",
    "    # It is assumed the dependent variable column is the last one.\n",
    "    # All rows are selected. All columns except last one is selected.\n",
    "    x = dataset.iloc[:, :-1].values\n",
    "    y = dataset.iloc[:, -1].values\n",
    "\n",
    "    \"\"\" Take care of missing data \"\"\"\n",
    "    # Check if there is missing data to be filled in\n",
    "    if ImputerInput[\"selectedCol\"] is not None:\n",
    "        # User has provided columns index which has missing data\n",
    "        from sklearn.impute import SimpleImputer\n",
    "\n",
    "        # Create the imputer object to be used on x, y\n",
    "        imputer = SimpleImputer(missing_values=np.nan,\n",
    "                                strategy=ImputerInput[\"strategy\"])\n",
    "\n",
    "        # Cycle through every column index provided by user\n",
    "        for colIndex in ImputerInput[\"selectedCol\"]:\n",
    "            # Link the imputer object to the numerical columns in x with the\n",
    "            # correct column index\n",
    "            # Need to reshape (-1, 1) each column for the imputer object to\n",
    "            # work and reshape it back (1, -1) to put back into x.\n",
    "            imputer.fit(x[:, colIndex].reshape(-1, 1))\n",
    "            # Perform the actual replacement on x\n",
    "            x[:, colIndex] = \\\n",
    "                imputer.transform(x[:, colIndex].reshape(-1, 1)).reshape(1, -1)\n",
    "    else:\n",
    "        # The selectedCol list is None. Hence no missing data.\n",
    "        pass\n",
    "\n",
    "    \"\"\" Encode categorical data \"\"\"\n",
    "    # Check if there is categorical data in x to encode\n",
    "    if xEncoderInput[\"cols\"] is not None:\n",
    "        # Column index had been provided by user to encode\n",
    "        from sklearn.compose import ColumnTransformer\n",
    "        from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "        # Cycle through each selected column index for encoding\n",
    "        for selectedCol in xEncoderInput[\"cols\"]:\n",
    "            # Create ColumnTransformer object\n",
    "            ct = ColumnTransformer(transformers=[(\"encoder\",\n",
    "                                                  OneHotEncoder(),\n",
    "                                                  [selectedCol])],\n",
    "                                   remainder=\"passthrough\")\n",
    "            # Fit and transform the ct object to x in one step\n",
    "            # Need to use np.array to force fit the result from fit_transform\n",
    "            # into a numpy array for subsequent analysis\n",
    "            x = np.array(ct.fit_transform(x))\n",
    "\n",
    "            # Remove first column of dummy variable to avoid dummy variable\n",
    "            # trap. The dummy variables are arranged in alphabetical order.\n",
    "            if xEncoderInput[\"AvoidDummy\"]:\n",
    "                # Need to avoid dummy variable trap because the model is unable\n",
    "                # to take care of the dummy variable\n",
    "                x = x[:, 1:]\n",
    "            else:\n",
    "                # Model is able to avoid dummy variable trap. Hence no need to\n",
    "                # remove any dummy variable.\n",
    "                pass\n",
    "    else:\n",
    "        # User did not provide any columns for encoding. So do nothing.\n",
    "        pass\n",
    "\n",
    "    # Check if need to encode dependent variable y\n",
    "    if yEncoderInput:\n",
    "        # Dependent variable y is categorical and need to be encoded\n",
    "        from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "        # Create LabelEncoder object\n",
    "        le = LabelEncoder()\n",
    "        # Fit_transfer LabelEncoder onto dependent variable y\n",
    "        y = le.fit_transform(y)\n",
    "    else:\n",
    "        # Dependent variable y is not categorical.\n",
    "        pass\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Module to Utilise the Data Pre-Processing Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Part01():\n",
    "    \"\"\" Data Preprocessing Inputs \"\"\"\n",
    "    # Data file name. File must be in same folder as script\n",
    "    Dataset = \"Part01Section02Data.csv\"\n",
    "    # Missing numerical data to be filled up\n",
    "    # Default values \"selectedCol\": [],\"strategy\": \"mean\"\n",
    "    ImputerInput = {\"selectedCol\": [1, 2], \"strategy\": \"mean\"}\n",
    "    # Columns in x with categorical data to encode, default {\"cols\": [],\n",
    "    #                                                   \"AvoidDummy\": False}\n",
    "    xEncoderInput = {\"cols\": [0], \"AvoidDummy\": False}\n",
    "    # Indicate if need to encode dependent variable y, enter True or False\n",
    "    yEncoderInput = True\n",
    "\n",
    "    x, y = Data_Preprocessing(Dataset, ImputerInput, xEncoderInput,\n",
    "                              yEncoderInput)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data imported successfully.\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Country    10 non-null     object \n",
      " 1   Age        9 non-null      float64\n",
      " 2   Salary     9 non-null      float64\n",
      " 3   Purchased  10 non-null     object \n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 448.0+ bytes\n",
      "None \n",
      "\n",
      "   Country   Age   Salary Purchased\n",
      "0   France  44.0  72000.0        No\n",
      "1    Spain  27.0  48000.0       Yes\n",
      "2  Germany  30.0  54000.0        No\n",
      "3    Spain  38.0  61000.0        No\n",
      "4  Germany  40.0      NaN       Yes\n",
      "[[1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "x, y = Part01()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
